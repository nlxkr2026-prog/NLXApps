import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from scipy.interpolate import griddata
<<<<<<< HEAD
from sklearn.cluster import KMeans  # Î†àÏù¥Ïñ¥ Î∂ÑÎ¶¨Î•º ÏúÑÌï¥ Ï∂îÍ∞Ä

# --- [1] Îç∞Ïù¥ÌÑ∞ Ï†ÑÏ≤òÎ¶¨ Î∞è Î†àÏù¥Ïñ¥ Î∂ÑÏÑù Î°úÏßÅ ---
=======

# --- [1] Îç∞Ïù¥ÌÑ∞ Ï†ÑÏ≤òÎ¶¨ Î∞è Pitch Í≥ÑÏÇ∞ Î°úÏßÅ (IQR ÌïÑÌÑ∞ÎßÅ Í≥†ÎèÑÌôî) ---
>>>>>>> 61426e3a005022eb34196b8b6d3d7fd3319dd467
def process_data(df, scale_factor, apply_iqr, apply_pitch_iqr):
    df.columns = [c.strip() for c in df.columns]
    
    # Îç∞Ïù¥ÌÑ∞ ÌÉÄÏûÖ ÌåêÎ≥Ñ
    if 'Height' in df.columns: d_type, target = "Height", "Height"
    elif 'Radius' in df.columns: d_type, target = "Radius", "Radius"
    elif 'Shift_Norm' in df.columns: d_type, target = "Shift", "Shift_Norm"
    else: return None, None

<<<<<<< HEAD
    # [Ï∂îÍ∞Ä] Î†àÏù¥Ïñ¥ ÏûêÎèô Î∂ÑÏÑù (Z-Position Í∏∞Î∞ò ÌÅ¥Îü¨Ïä§ÌÑ∞ÎßÅ)
    # ZÍ∞íÏùò Ï∞®Ïù¥Í∞Ä ÎØ∏ÏÑ∏ÌïòÎØÄÎ°ú ÌÅ¥Îü¨Ïä§ÌÑ∞ÎßÅÏùÑ ÌÜµÌï¥ Ï∏µÏùÑ Íµ¨Î∂ÑÌï©ÎãàÎã§.
    z_values = df['Bump_Center_Z'].values.reshape(-1, 1)
    
    # ÏóòÎ≥¥Ïö∞ Ìè¨Ïù∏Ìä∏ ÎåÄÏã† ÏµúÎåÄ 5Í∞ú Ï∏µÍπåÏßÄ ÌÉêÏÉâÌïòÏó¨ ÏµúÏ†ÅÏùò Ï∏µ Ïàò Í≥ÑÏÇ∞ (Í∞ÑÎã®Ìïú Î°úÏßÅ)
    # Ïã§Î¨¥Ï†ÅÏúºÎ°úÎäî ÏÇ¨Ïö©ÏûêÍ∞Ä Ï∏µ ÏàòÎ•º ÏûÖÎ†•ÌïòÍ≤å Ìï† ÏàòÎèÑ ÏûàÏäµÎãàÎã§.
    n_clusters = 1
    if len(df) > 10:
        # ZÍ∞íÏùò Í≥†Ïú†Í∞í Î≤îÏúÑÎ•º Î≥¥Í≥† ÎåÄÎûµÏ†ÅÏù∏ Ï∏µÏàò Ï∂îÏ†ï (Ï∞®Ïù¥Í∞Ä 0.005 Ïù¥ÏÉÅÏùº Îïå Íµ¨Î∂Ñ Îì±)
        z_range = np.ptp(df['Bump_Center_Z'])
        if z_range > 0.01: n_clusters = 2 # ÏòàÏãú ÏûÑÍ≥ÑÏπò
        if z_range > 0.05: n_clusters = 3
    
    # ÏÇ¨Ïù¥ÎìúÎ∞îÏóêÏÑú ÏÑ†ÌÉùÌï† Ïàò ÏûàÎèÑÎ°ù ÏùºÎã® 1~5Ï∏µ ÏÇ¨Ïù¥ÏóêÏÑú ÏûêÎèô Ìï†ÎãπÌïòÍ±∞ÎÇò 
    # ÏïÑÎûò Î©îÏù∏ Î£®ÌîÑÏóêÏÑú ÏÇ¨Ïö©ÏûêÍ∞Ä ÏßÄÏ†ïÌïú n_layersÎ•º ÏÇ¨Ïö©Ìï† Ïàò ÏûàÏäµÎãàÎã§.
    
    # Í∏∞Î≥∏ Îã®ÏúÑ Î≥ÄÌôò
    df['X'] = df['Bump_Center_X'] * scale_factor
    df['Y'] = df['Bump_Center_Y'] * scale_factor
    df['Z_um'] = df['Bump_Center_Z'] * scale_factor
    df['Value'] = df[target] * scale_factor
    
    # 1Ï∞®: Î©îÏù∏ Value IQR Ï†úÍ±∞
=======
    # Í∏∞Î≥∏ Îã®ÏúÑ Î≥ÄÌôò
    df['X'] = df['Bump_Center_X'] * scale_factor
    df['Y'] = df['Bump_Center_Y'] * scale_factor
    df['Value'] = df[target] * scale_factor
    
    # 1Ï∞®: Î©îÏù∏ Value(Height/Radius/Shift) IQR Ï†úÍ±∞
>>>>>>> 61426e3a005022eb34196b8b6d3d7fd3319dd467
    df_clean = df[df['Value'] != 0].copy()
    if apply_iqr:
        q1, q3 = df_clean['Value'].quantile([0.25, 0.75])
        iqr = q3 - q1
        df_clean = df_clean[(df_clean['Value'] >= q1 - 1.5 * iqr) & (df_clean['Value'] <= q3 + 1.5 * iqr)]

<<<<<<< HEAD
    # 2Ï∞®: Pitch Í≥ÑÏÇ∞
=======
    # 2Ï∞®: Pitch Í≥ÑÏÇ∞ (Í∑∏Î¶¨Îìú Í∏∞Î∞ò)
>>>>>>> 61426e3a005022eb34196b8b6d3d7fd3319dd467
    df_clean['Y_grid'] = df_clean['Y'].round(0)
    df_clean = df_clean.sort_values(by=['Y_grid', 'X'])
    df_clean['X_Pitch'] = df_clean.groupby('Y_grid')['X'].diff()

    df_clean['X_grid'] = df_clean['X'].round(0)
    df_clean = df_clean.sort_values(by=['X_grid', 'Y'])
    df_clean['Y_Pitch'] = df_clean.groupby('X_grid')['Y'].diff()

<<<<<<< HEAD
    # 3Ï∞®: Pitch IQR ÌïÑÌÑ∞ÎßÅ
=======
    # 3Ï∞®: [Ï∂îÍ∞Ä] Pitch Îç∞Ïù¥ÌÑ∞ IQR ÌïÑÌÑ∞ÎßÅ (ÏÑ†ÌÉù ÏÇ¨Ìï≠)
>>>>>>> 61426e3a005022eb34196b8b6d3d7fd3319dd467
    if apply_pitch_iqr:
        for col in ['X_Pitch', 'Y_Pitch']:
            p_data = df_clean[col].dropna()
            if not p_data.empty:
                pq1, pq3 = p_data.quantile([0.25, 0.75])
                piqr = pq3 - pq1
<<<<<<< HEAD
=======
                # Ïù¥ÏÉÅÏπòÏóê Ìï¥ÎãπÌïòÎäî ÌñâÏùò Pitch Í∞íÎßå NaNÏúºÎ°ú Ï≤òÎ¶¨ÌïòÏó¨ ÌÜµÍ≥Ñ/Í∑∏ÎûòÌîÑÏóêÏÑú Ï†úÏô∏
>>>>>>> 61426e3a005022eb34196b8b6d3d7fd3319dd467
                df_clean.loc[(df_clean[col] < pq1 - 1.5 * piqr) | (df_clean[col] > pq3 + 1.5 * piqr), col] = np.nan

    return df_clean, d_type

# --- [2] UI Íµ¨ÏÑ± ---
<<<<<<< HEAD
st.set_page_config(page_title="NLX Multi-Layer Analyzer", layout="wide")
st.title("üî¨ NLX Bump Analysis Dashboard (Layer Analysis)")

st.sidebar.header("üìÅ Data & Layer Settings")
uploaded_files = st.sidebar.file_uploader("Upload CSV Files", type=['csv'], accept_multiple_files=True)
scale = st.sidebar.number_input("Global Scale Factor", value=1000)

# [Ï∂îÍ∞Ä] Î†àÏù¥Ïñ¥ Î∂ÑÎ¶¨ ÏÑ§Ï†ï
n_layers = st.sidebar.slider("Number of expected layers (Z-axis)", 1, 5, 1)

st.sidebar.subheader("üõ°Ô∏è Outlier Removal Settings")
use_val_iqr = st.sidebar.checkbox("Apply IQR to Value", value=True)
use_pitch_iqr = st.sidebar.checkbox("Apply IQR to Pitch", value=True)

if uploaded_files:
    all_data = []
    
    for file in uploaded_files:
        raw_df = pd.read_csv(file)
        p_df, d_type = process_data(raw_df, scale, use_val_iqr, use_pitch_iqr)
        
        if p_df is not None:
            # ZÏ∂ï ÌÅ¥Îü¨Ïä§ÌÑ∞ÎßÅ ÏàòÌñâ (Î†àÏù¥Ïñ¥ Ìï†Îãπ)
            if n_layers > 1:
                kmeans = KMeans(n_clusters=n_layers, random_state=42)
                p_df['Layer'] = kmeans.fit_predict(p_df[['Bump_Center_Z']])
                # ZÍ∞í ÌèâÍ∑† ÏàúÏÑúÎåÄÎ°ú Î†àÏù¥Ïñ¥ Ïù¥Î¶Ñ Ïû¨Ï†ïÎ†¨ (0Ï∏µÏù¥ Í∞ÄÏû• ÎÇÆÏùÄ Ï∏µÏù¥ ÎêòÎèÑÎ°ù)
                layer_order = p_df.groupby('Layer')['Bump_Center_Z'].mean().sort_values().index
                layer_map = {old: new for new, old in enumerate(layer_order)}
                p_df['Layer'] = p_df['Layer'].map(layer_map)
            else:
                p_df['Layer'] = 0
                
            p_df['Source'] = file.name
            all_data.append(p_df)

    combined_df = pd.concat(all_data)

    # Î†àÏù¥Ïñ¥ ÌïÑÌÑ∞ÎßÅ UI
    st.sidebar.markdown("---")
    unique_layers = sorted(combined_df['Layer'].unique())
    selected_layer = st.sidebar.selectbox("Select Layer to View", ["All Layers"] + [f"Layer {i}" for i in unique_layers])

    # Îç∞Ïù¥ÌÑ∞ ÌïÑÌÑ∞ÎßÅ Ïã§Ìñâ
    if selected_layer != "All Layers":
        layer_num = int(selected_layer.split(" ")[1])
        display_df = combined_df[combined_df['Layer'] == layer_num]
    else:
        display_df = combined_df

    # ÏÉÅÎã® ÏöîÏïΩ ÏöîÏïΩ
    st.subheader(f"üìä Statistics Summary ({selected_layer})")
    summary_list = []
    for src in display_df['Source'].unique():
        sub = display_df[display_df['Source'] == src]
        summary_list.append({
            "File": src, "Avg": sub['Value'].mean(), "3-Sigma": sub['Value'].std()*3,
            "Count": len(sub)
        })
    st.dataframe(pd.DataFrame(summary_list))

    # [Ïù¥ÌõÑ ÏãúÍ∞ÅÌôî Î°úÏßÅÏùÄ display_dfÎ•º ÏÇ¨Ïö©ÌïòÏó¨ Í∏∞Ï°¥Í≥º ÎèôÏùºÌïòÍ≤å ÏßÑÌñâ...]
    # (ÏÉùÎûµ: Í∏∞Ï°¥ ÏΩîÎìúÏùò ÏãúÍ∞ÅÌôî Î∂ÄÎ∂ÑÏóêÏÑú plot_dfÎ•º display_df Í∏∞Î∞òÏúºÎ°ú ÌïÑÌÑ∞ÎßÅÌïòÏó¨ ÏÇ¨Ïö©)
=======
st.set_page_config(page_title="NLX Professional Analyzer", layout="wide")
st.title("üî¨ NLX Bump Analysis Dashboard (IQR Advanced)")

# ÏÇ¨Ïù¥ÎìúÎ∞î: IQR ÏòµÏÖò ÏÑ∏Î∂ÑÌôî
st.sidebar.header("üìÅ Data & Filtering")
uploaded_files = st.sidebar.file_uploader("Upload CSV Files", type=['csv'], accept_multiple_files=True)
scale = st.sidebar.number_input("Global Scale Factor (mm to um = 1000)", value=1000)

st.sidebar.subheader("üõ°Ô∏è Outlier Removal Settings")
use_val_iqr = st.sidebar.checkbox("Apply IQR to Value (H/R/S)", value=True)
use_pitch_iqr = st.sidebar.checkbox("Apply IQR to Pitch (X/Y)", value=True) # Ï∂îÍ∞ÄÎêú ÏòµÏÖò

if uploaded_files:
    all_data = []
    summary_list = []

    for file in uploaded_files:
        raw_df = pd.read_csv(file)
        # ÌîºÏπò IQR ÏòµÏÖò Ï†ÑÎã¨
        p_df, d_type = process_data(raw_df, scale, use_val_iqr, use_pitch_iqr)
        
        if p_df is not None:
            p_df['Source'] = file.name
            all_data.append(p_df)
            
            v = p_df['Value'].dropna()
            xp = p_df['X_Pitch'].dropna()
            yp = p_df['Y_Pitch'].dropna()
            
            summary_list.append({
                "File": file.name, "Type": d_type, 
                "Avg": v.mean(), "3-Sigma": v.std()*3,
                "X_Pitch Avg": xp.mean(), "X_Pitch 3œÉ": xp.std()*3,
                "Y_Pitch Avg": yp.mean(), "Y_Pitch 3œÉ": yp.std()*3,
                "Count": len(v)
            })

    combined_df = pd.concat(all_data)
    
    # ÏÉÅÎã® ÏöîÏïΩ ÏöîÏïΩ (Pitch IQR Î∞òÏòÅÎê®)
    st.subheader("üìä Statistics Summary (IQR Applied)")
    st.dataframe(pd.DataFrame(summary_list).style.highlight_min(axis=0, subset=['3-Sigma', 'X_Pitch 3œÉ']))

    # ÏÉÅÏÑ∏ Î∂ÑÏÑù ÎåÄÏÉÅ ÏÑ†ÌÉù
    target_file = st.selectbox("Select File for Detail View", [f.name for f in uploaded_files])
    plot_df = combined_df[combined_df['Source'] == target_file]

    # ÏÉÅÏÑ∏ ÏàòÏπò ÌÖåÏù¥Î∏î
    st.markdown("---")
    st.write(f"### üî¢ Detailed Numerical Report: {target_file}")
    col_stat1, col_stat2 = st.columns([1, 2])
    with col_stat1:
        st.write("**Pitch Statistics (Filtered)**")
        p_stats = plot_df[['X_Pitch', 'Y_Pitch']].describe().loc[['mean', 'std']]
        p_stats.loc['3-Sigma'] = p_stats.loc['std'] * 3
        st.table(p_stats)

    # --- [3] ÏãúÍ∞ÅÌôî Ïª§Ïä§ÌÑ∞ÎßàÏù¥Ïßï Î∞è Ïã§Ìñâ ---
    st.subheader("üé® Plot Settings")
    c1, c2, c3, c4 = st.columns(4)
    plots_meta = {
        "Contour": {"title": f"{d_type} Map", "xl": "X (um)", "yl": "Y (um)"},
        "Histogram": {"title": f"{d_type} Dist", "xl": "Value", "yl": "Freq"},
        "Pitch": {"title": "Pitch Spread (IQR Applied)", "xl": "Axis", "yl": "Pitch (um)"},
        "Boxplot": {"title": "Total Comparison", "xl": "File", "yl": "Value"}
    }
    
    config = {}
    for i, (k, v) in enumerate(plots_meta.items()):
        with [c1, c2, c3, c4][i]:
            t = st.text_input(f"Title ({k})", v['title'])
            xl = st.text_input(f"X ({k})", v['xl'])
            yl = st.text_input(f"Y ({k})", v['yl'])
            m_sc = st.checkbox(f"Manual Scale ({k})")
            y_lim = None
            if m_sc:
                # ÌîºÏπò Í∑∏ÎûòÌîÑÏùº Í≤ΩÏö∞ ÌîºÏπò Îç∞Ïù¥ÌÑ∞ Í∏∞Ï§ÄÏúºÎ°ú Ï¥àÍ∏∞Í∞í ÏÑ§Ï†ï
                ref_data = plot_df['X_Pitch'] if k == "Pitch" else plot_df['Value']
                y_min = st.number_input(f"Min_{k}", value=0.0)
                y_max = st.number_input(f"Max_{k}", value=float(ref_data.max()))
                y_lim = (y_min, y_max)
            config[k] = {"t": t, "xl": xl, "yl": yl, "ylim": y_lim}

    # Í∑∏ÎûòÌîÑ Í∑∏Î¶¨Í∏∞
    st.markdown("---")
    fig, axes = plt.subplots(2, 2, figsize=(16, 12))
    
    # 1. Contour
    ax1 = axes[0, 0]
    xi = np.linspace(plot_df['X'].min(), plot_df['X'].max(), 100)
    yi = np.linspace(plot_df['Y'].min(), plot_df['Y'].max(), 100)
    xi, yi = np.meshgrid(xi, yi)
    zi = griddata((plot_df['X'], plot_df['Y']), plot_df['Value'], (xi, yi), method='linear')
    cp = ax1.contourf(xi, yi, zi, cmap='viridis', levels=15)
    plt.colorbar(cp, ax=ax1)
    ax1.set_title(config["Contour"]["t"]); ax1.set_xlabel(config["Contour"]["xl"]); ax1.set_ylabel(config["Contour"]["yl"])
    if config["Contour"]["ylim"]: ax1.set_ylim(config["Contour"]["ylim"])

    # 2. Histogram
    ax2 = axes[0, 1]
    sns.histplot(plot_df['Value'], kde=True, ax=ax2, color='skyblue')
    ax2.set_title(config["Histogram"]["t"]); ax2.set_xlabel(config["Histogram"]["xl"]); ax2.set_ylabel(config["Histogram"]["yl"])
    if config["Histogram"]["ylim"]: ax2.set_xlim(config["Histogram"]["ylim"])

    # 3. Pitch Boxplot (IQR Î∞òÏòÅÎêú Îç∞Ïù¥ÌÑ∞ ÏÇ¨Ïö©)
    ax3 = axes[1, 0]
    pitch_melt = plot_df[['X_Pitch', 'Y_Pitch']].melt(var_name='Type', value_name='Pitch')
    sns.boxplot(x='Type', y='Pitch', data=pitch_melt, ax=ax3, palette='Set2')
    ax3.set_title(config["Pitch"]["t"]); ax3.set_xlabel(config["Pitch"]["xl"]); ax3.set_ylabel(config["Pitch"]["yl"])
    if config["Pitch"]["ylim"]: ax3.set_ylim(config["Pitch"]["ylim"])

    # 4. Global Boxplot
    ax4 = axes[1, 1]
    sns.boxplot(x='Source', y='Value', data=combined_df, ax=ax4)
    ax4.set_title(config["Boxplot"]["t"]); ax4.set_xlabel(config["Boxplot"]["xl"]); ax4.set_ylabel(config["Boxplot"]["yl"])
    if config["Boxplot"]["ylim"]: ax4.set_ylim(config["Boxplot"]["ylim"])

    plt.tight_layout()
    st.pyplot(fig)

else:
    st.info("üí° ÏÇ¨Ïù¥ÎìúÎ∞îÏóêÏÑú CSV ÌååÏùºÎì§ÏùÑ ÏóÖÎ°úÎìúÌïòÏÑ∏Ïöî.")
>>>>>>> 61426e3a005022eb34196b8b6d3d7fd3319dd467
